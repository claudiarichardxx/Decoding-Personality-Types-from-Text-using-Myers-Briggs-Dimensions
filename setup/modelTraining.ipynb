{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPK5v1K/yutycYGAWNXAFN+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiarichardxx/Decoding-Personality-Types-from-Text-using-Myers-Briggs-Dimensions/blob/main/setup/modelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installs and imports"
      ],
      "metadata": {
        "id": "BdVA-RfDOapV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8EsenlLNQQm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U accelerate\n",
        "!pip install -U transformers\n",
        "!pip install iterative-stratification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from transformers import EvalPrediction\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "import torch"
      ],
      "metadata": {
        "id": "ARGZ4xSHNScy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the data"
      ],
      "metadata": {
        "id": "vcIe4BvAPT8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"ClaudiaRichard/mbti_classification_v2\")"
      ],
      "metadata": {
        "id": "eYsNFkE0PW6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAFPxfmxBssf",
        "outputId": "ed5514a0-0327-49c6-e550-490e962ef657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['I/E', 'N/S', 'T/F', 'J/P', 'post'],\n",
              "        num_rows: 95166\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['I/E', 'N/S', 'T/F', 'J/P', 'post'],\n",
              "        num_rows: 38067\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['I/E', 'N/S', 'T/F', 'J/P', 'post'],\n",
              "        num_rows: 25377\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding the data"
      ],
      "metadata": {
        "id": "2AxuKJ23OYCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples):\n",
        "  # take a batch of texts\n",
        "  text = examples[\"post\"]\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
        "  # add labels\n",
        "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "kEbsp00PNWBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = ['ClaudiaRichard/mbti-bert-nli-finetuned', 'ClaudiaRichard/bert-finetuned-sem_eval-english','sentence-transformers/bert-base-nli-mean-tokens']\n",
        "tokenizer = AutoTokenizer.from_pretrained(mode[2], device)"
      ],
      "metadata": {
        "id": "gmB_8nB7NoGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8901824fd4624f3bba90b7334f29a465",
            "936d375b39894fe3933e582e53985dd6",
            "543614855b4540dd980cc3c71776f450",
            "3e8c517303004f309be016e0805bad6a",
            "4cc42461759242dabf453a94c626a520",
            "cc4423f8c2034975b49f97832778f1b6",
            "42e687dce02a49c2a493cd731f762dea",
            "31b119e797e847c9b3af6d6ece55acf7",
            "2c008019529a4d7890aca86c0c0da853",
            "ebd2f00b47f74d9889eff8848b5dff57",
            "36048646418c4dc0b0d8336e1fef3168",
            "bfd2d5ce65484af4a94bb6bd0e1b2500",
            "03a19be8a7384694b79a50c923c0c3cf",
            "7220382d276f434d960e825d1e041974",
            "9edfd6fc4b4540eda880be87228ca20f",
            "605f0d8007e646c390df201747a26ac5",
            "fed857d399fc424691b467f1bc2f55ec",
            "e97b62d91e3449199425712e41d54a65",
            "e9ab659145a847428c076fca4da41bd3",
            "ca024bd93b3846febf0830e873bf43c1",
            "1ba0808b38e044e29b24d269a2cb808e",
            "c1046ccbf06f4d48a84e1d6438c968db",
            "35deb733824e4541b92d58b9010bec3f",
            "25644d57a3064e44b092dc676835f263",
            "cab7592f90b04cc6a4250551ce30b3c1",
            "1ee34e045bed45c4908f46e0dce69e3a",
            "399712ca3946479cb28476ab67c950ec",
            "928ff30012694c11b943b8827d83403e",
            "00a7799fdb9c48de9a2d2db8f3876eaf",
            "2f12a729200449218970b24d8e56b71b",
            "185689c4811144e1bc7c0d377910c854",
            "0ce7016a7f1c44139b4fae687c9427d9",
            "3558e1cf75044c718bef61e1a6f69bd8"
          ]
        },
        "id": "C9DaC4iZLqeJ",
        "outputId": "8fdf2cfb-2042-4f2c-e9c1-977886834a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/95166 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8901824fd4624f3bba90b7334f29a465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/38067 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfd2d5ce65484af4a94bb6bd0e1b2500"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25377 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35deb733824e4541b92d58b9010bec3f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = encoded_dataset['train'][50]\n",
        "print(example.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh6ABjpsLy3q",
        "outputId": "4c244d7f-f7a8-4f02-fec9-1290134b5753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "v_YnRR-dMHky",
        "outputId": "725710fb-1806-4c30-ffc4-e2907d754e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] two months? i wouldn't be crazy about the idea. if you are really his best employee, then that's what may be cooking him. who wants their most reliable asset gone for that long? entj employer... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dataset.set_format(\"torch\")\n",
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI2zGd0pMbEW",
        "outputId": "04bf7259-4250-4029-c7f1-83ca9d915448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "YZbQ1rs3Oh7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id\n",
        "                                                           )"
      ],
      "metadata": {
        "id": "1ESCd-ruNtow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "metric_name = \"f1\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"mbti-bert-nli-finetuned_v2\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs = 2,\n",
        "    fp16=True,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        ")"
      ],
      "metadata": {
        "id": "pJQCGvkDOrW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MBTITrainer(Trainer):\n",
        "\n",
        "    def __init__(self, *args, class_weights = None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if class_weights is not None:\n",
        "            class_weights = class_weights.to(self.args.device)\n",
        "\n",
        "        self.loss_fct = torch.nn.BCEWithLogitsLoss(weight=class_weights)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        \"\"\"\n",
        "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
        "        Subclass and override for custom behavior.\n",
        "        \"\"\"\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        try:\n",
        "            loss = self.loss_fct(outputs.logits.view(-1, model.num_labels), labels.view(-1, model.num_labels).float())\n",
        "        except AttributeError:\n",
        "            loss = self.loss_fct(outputs.logits.view(-1, model.module.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ],
      "metadata": {
        "id": "EVPVVp70OktA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # Apply threshold to convert logits to binary predictions\n",
        "    y_pred = (predictions >= threshold).astype(np.float32)\n",
        "\n",
        "    # Compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average='micro')\n",
        "\n",
        "    # Return metrics as a dictionary\n",
        "    metrics = {'f1': f1_micro_average, 'roc_auc': roc_auc}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ],
      "metadata": {
        "id": "cLn_1QBYO2_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MBTITrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "lO3Vsw7rPDc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "D1oF6fQJaZXf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "8df40a3f-380d-4bf6-b325-5f198a9b8731"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10951' max='11896' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10951/11896 32:17 < 02:47, 5.65 it/s, Epoch 1.84/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541300</td>\n",
              "      <td>0.538476</td>\n",
              "      <td>0.572146</td>\n",
              "      <td>0.676641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11896' max='11896' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11896/11896 36:12, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541300</td>\n",
              "      <td>0.538476</td>\n",
              "      <td>0.572146</td>\n",
              "      <td>0.676641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.504600</td>\n",
              "      <td>0.542942</td>\n",
              "      <td>0.523148</td>\n",
              "      <td>0.654622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11896, training_loss=0.5312848633058775, metrics={'train_runtime': 2172.377, 'train_samples_per_second': 87.615, 'train_steps_per_second': 5.476, 'total_flos': 1.2519838164307968e+16, 'train_loss': 0.5312848633058775, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(eval_dataset=encoded_dataset['test'])"
      ],
      "metadata": {
        "id": "iwyCMDv7PKMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "lFRKLcMkPu0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(\"ClaudiaRichard/mbti_classification_v2/\")"
      ],
      "metadata": {
        "id": "W14i_7YTPRUm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}