{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNc9/kHRiZhcRjZCO15iDvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiarichardxx/Decoding-Personality-Types-from-Text-using-Myers-Briggs-Dimensions/blob/main/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning the repo"
      ],
      "metadata": {
        "id": "buUUkxgzxLw6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVFf9gPsGcNX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/claudiarichardxx/Decoding-Personality-Types-from-Text-using-Myers-Briggs-Dimensions.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL1ik7JuGhE7",
        "outputId": "4bc539e8-a1bd-4737-d977-94663493bf5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Decoding-Personality-Types-from-Text-using-Myers-Briggs-Dimensions\n"
          ]
        }
      ],
      "source": [
        "cd /content/Decoding-Personality-Types-from-Text-using-Myers-Briggs-Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "from IPython.display import display, HTML\n",
        "from pipeline import Pipeline"
      ],
      "metadata": {
        "id": "RMwjVPfLrDBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from utils.predict import Predictions\n",
        "from utils.attributions import Attributions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "lwLCE0ZbMmaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "94SeWEQOxomT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"ClaudiaRichard/mbti_classification_dataset_fullPosts\") #ClaudiaRichard/mbti_classification_v2\n",
        "df_pandas = pd.DataFrame(dataset['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "b470ad3cb6384a3bbcc3c21cddc2b5b9",
            "c3b06ac65fff4cfb8812844a899106e6",
            "a9f58640a2a4432e8becd3c1f2fe34ee",
            "e8d3b616252b4299a26c49d72c9b623b",
            "925c144e47a140bcae0f4d20fb636cd5",
            "bfb7e827dbc04bb7a57b30aa1ae70245",
            "d86e24fbf22b4741af5982e644791b2f",
            "3d2396aa901748ab9848f832029e4a62",
            "1a3409fa045f4f4386d47dba4db778aa",
            "8548ff2da8e94ade9cb0b14dc61f232c",
            "8e2279aa299b4c118ddbcd6da064512f",
            "c692234eec404d53a16faf42f3214184",
            "085a9fb4a92f4cffbd825ef2d9d7a684",
            "e97cd0c249ca418aaf758d2a44b8c80b",
            "b4c9446c25724fb8bef5f9dd5153920a",
            "b9699bc1beb8439290e8d734b2a82d9c",
            "fdcbde6fab36464289b83f900f0d90f4",
            "8442c70b5d3d4e7ca8b031c56c1494a2",
            "1a7f63976e2043e085f389b412594c9e",
            "291a4cb8a859472f8a93bd11f09a89e4",
            "ad0d5b9cf8c84389aad1e40e9d7ed77f",
            "1fdb3a4555a84121b10c107430d30c25",
            "31ff435527704dc1b3dafc55c65d749f",
            "4c30d5bb272c45658358ae24273fd1fc",
            "c131f7eaa22a46f6a70514f98c4df834",
            "68aa4c5a69084cb8947affcac7952389",
            "dc05304b82fb4693bdc07d9285047f1a",
            "4767076e264040bc8eadf277d5efdca8",
            "f1c70af287554c49ad4b7a1b57636c4f",
            "d9aa1f1360eb4467b8cf671a783d0972",
            "f45f34c0adbb47b8aeb180a513c3cf02",
            "8b5682d2eeb745aab84ad81f0bd04811",
            "1b300db64d75428583b236fb7b00b179",
            "219fb367f6b7424485e0f32b14c2539d",
            "479abbc437ad476bb62da34d518ba898",
            "7012a5ff33e74b9da47b3ce2cb51ac60",
            "a7ff6172df3844eb8cfafefa53dd6f6c",
            "d7ef770d6f3c4b458ca285a3b8d71989",
            "a36aac807a444831954f3c50ae9269cd",
            "d91d45583f04413da11339f5293af59c",
            "b04fdcce35784b58a504b9f316a8b6c8",
            "96ea5af9dcea4e47bba129fef129043e",
            "8dc5fac772af4663b738f8c8eecff259",
            "7e971d2f58c448528a1b5ab375cc9f52",
            "52eba5d7d3844b4d91d3b27928670f60",
            "92cdb50ef5974b3b8742ec762974fd66",
            "373f013462e348f8a275452ba373dd71",
            "4da225d1846d416a8de8b5c9ced9df8e",
            "64751e7b811e4f828adfcbaae407d6b5",
            "29d2b6376f48452d8bc0ef0a805f2514",
            "05c8bdc7ce394300a2b7a9f5dfc2e3f4",
            "3767abec1c2440fdbb2a406dc114a1d5",
            "d07538777e5b4f64b9bff2fcd56cd8d6",
            "2c8cb541592f434d85b07d9927bd30b3",
            "eda9e734d4d143efa91b06bfd64bc779",
            "cdca428e95134da796054d0954b89a50",
            "f69220eb63ca4550b111d7a3812d538d",
            "08a0bd49d1354c0a80a0fbc1bf5378a5",
            "046d0cdb6936459984164369a66b8dda",
            "fe4844ee8df54c8ebc4cf7209fea1d65",
            "e5b77233922a426994ca04b593471a0b",
            "f817dfdb8fe04b22be34364ee768afee",
            "a073497a23e84e40b80c7f7d4b26e1ea",
            "58e527b2b7ec485e9b29a5bab0b44749",
            "0a7d49a84791496aac5b0ba7a89f913c",
            "39ad176701b046789218fd5a4d7ec3b3",
            "262773644dcc41f2918cf066a7b46075",
            "3ad03f7a66594e61b955c79c8e75a36f",
            "4c6ffc96e30d4baf9a41508081b34f93",
            "1afcd48eef874bb29029300dad316681",
            "4ecc34d2c4464066a7cdd11f96e66e5c",
            "ec007e4fc1cf44d4a88983d7f8cf4606",
            "97b16d2810cf4fbea0ad15702cb0f4ad",
            "4dbf29f46ea34ee384855edcaa1c9cdc",
            "4fb2e0441e874f609653d5a340ddf93e",
            "1c647fb5e1cd4341b85ea842d984c012",
            "97c0aad9a7fb4c36ad536ebd3fe43278"
          ]
        },
        "id": "c6-Ulpo8MuwF",
        "outputId": "abe613d5-9c6c-4f16-e53a-9c56738f8a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b470ad3cb6384a3bbcc3c21cddc2b5b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/24.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c692234eec404d53a16faf42f3214184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ff435527704dc1b3dafc55c65d749f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/6.40M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219fb367f6b7424485e0f32b14c2539d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/5205 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52eba5d7d3844b4d91d3b27928670f60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2082 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdca428e95134da796054d0954b89a50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262773644dcc41f2918cf066a7b46075"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "RUdddEAkxl44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model_name, text, threshold = [-0.5, 0.5]):\n",
        "\n",
        "        labs = {0: ['Introvert', 'Extrovert'], 1: ['Intuition', 'Sensing'], 2: ['Thinking', 'Feeling'], 3: ['Judging', 'Perceiving']}\n",
        "        pred = Predictions()\n",
        "        attribute = Attributions()\n",
        "        #model = AutoModelForSequenceClassification.from_pretrained(\"model/bert/\")\n",
        "        #tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer/\")\n",
        "        pred.load_model(model_name)\n",
        "        text = text.replace('|||', '[SEP]')\n",
        "        encoded, labels = pred.tokenizer(text, padding = True, return_attention_mask = True, return_tensors=\"pt\"), pred.predict_labels(text)\n",
        "        attribution_th = []\n",
        "        labels = list(map(int, labels))\n",
        "        attribute.initialize(pred.model)\n",
        "        #tokens = pred.tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"][0])\n",
        "        atts = []\n",
        "        for i in range(0,4):\n",
        "\n",
        "            attributions = attribute.getAttributions(encoded, i)\n",
        "            atts.append(attributions)\n",
        "            #print(self.labels)\n",
        "            #self.labels = list(self.labels)\n",
        "\n",
        "            if(checkThreshold(attributions, label = int(labels[i]), threshold = threshold)):\n",
        "                attribution_th.append(labels[i])\n",
        "            else:\n",
        "                attribution_th.append(2)\n",
        "\n",
        "        return labels, attribution_th, atts\n",
        "\n",
        "def checkThreshold(attributions, label, threshold = [-0.3, 0.6]):\n",
        "\n",
        "        if(label == 0):\n",
        "            if(any(attributions[0]<= threshold[0])):\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        if(label == 1):\n",
        "            if(any(attributions[0] >= threshold[1])):\n",
        "                return True\n",
        "            else:\n",
        "                return False"
      ],
      "metadata": {
        "id": "Ate2_YoIM4UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#odel_name = 'ClaudiaRichard/mbti-bert-nli-finetuned'\n",
        "model_name = 'ClaudiaRichard/all-MiniLM-L12-v2_mbti_full'"
      ],
      "metadata": {
        "id": "JHRyJ_9wM51U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formTrueLabels(first, second, third, fourth):\n",
        "    return [first, second, third, fourth]"
      ],
      "metadata": {
        "id": "WQy6KB73M_VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas['True'] = df_pandas.apply(lambda x: formTrueLabels(x['I/E'], x['N/S'], x['T/F'], x['J/P']),axis=1)\n",
        "df_pandas['raw'] = [[] for i in range(len(df_pandas))]\n",
        "df_pandas['filtered'] = [[] for i in range(len(df_pandas))]\n",
        "df_pandas['attributions'] = [[] for i in range(len(df_pandas))]"
      ],
      "metadata": {
        "id": "k01uClPoNACz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_pandas)):\n",
        "    #print(df_pandas.iloc[i]['post'])\n",
        "    text = df_pandas.iloc[i]['post'][:500]\n",
        "    raw, filtered, atts = evaluate(model_name, text, threshold = [-0.3, 0.6])\n",
        "    print(raw)\n",
        "    df_pandas.at[i, 'raw'] = raw\n",
        "    df_pandas.at[i, 'filtered'] = filtered\n",
        "    df_pandas.at[i, 'attributions'] = atts"
      ],
      "metadata": {
        "id": "EhDNNoi1NFq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "NhFZ2W7-KijX",
        "outputId": "bc4f3fb1-d2f6-47fa-bf44-ae121fd943df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   I/E  N/S  T/F  J/P                                               post  \\\n",
              "0    0    0    0    0  'Dear INTP,   I enjoyed our conversation the o...   \n",
              "1    0    0    0    0  'I tend to build up a collection of things on ...   \n",
              "2    1    0    1    0  'https://www.youtube.com/watch?v=PLAaiKvHvZs||...   \n",
              "3    0    0    0    0  'Fair enough, if that's how you want to look a...   \n",
              "4    1    0    1    1  'He doesn't want to go on the trip without me,...   \n",
              "\n",
              "           True           raw      filtered  \\\n",
              "0  [0, 0, 0, 0]  [1, 0, 0, 0]  [1, 0, 0, 0]   \n",
              "1  [0, 0, 0, 0]  [0, 0, 0, 1]  [0, 0, 0, 1]   \n",
              "2  [1, 0, 1, 0]  [0, 0, 1, 1]  [0, 0, 1, 2]   \n",
              "3  [0, 0, 0, 0]  [0, 0, 1, 0]  [0, 0, 1, 0]   \n",
              "4  [1, 0, 1, 1]  [0, 0, 1, 0]  [0, 0, 1, 0]   \n",
              "\n",
              "                                        attributions  \n",
              "0  [[[tensor(-0.0522, dtype=torch.float64), tenso...  \n",
              "1  [[[tensor(-0.0591, dtype=torch.float64), tenso...  \n",
              "2  [[[tensor(-0.1823, dtype=torch.float64), tenso...  \n",
              "3  [[[tensor(-0.0953, dtype=torch.float64), tenso...  \n",
              "4  [[[tensor(-0.1624, dtype=torch.float64), tenso...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b83fcfe4-9bf3-4dbd-88b9-cca80947129b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>I/E</th>\n",
              "      <th>N/S</th>\n",
              "      <th>T/F</th>\n",
              "      <th>J/P</th>\n",
              "      <th>post</th>\n",
              "      <th>True</th>\n",
              "      <th>raw</th>\n",
              "      <th>filtered</th>\n",
              "      <th>attributions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[[[tensor(-0.0522, dtype=torch.float64), tenso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>'I tend to build up a collection of things on ...</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[[[tensor(-0.0591, dtype=torch.float64), tenso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>'https://www.youtube.com/watch?v=PLAaiKvHvZs||...</td>\n",
              "      <td>[1, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 1]</td>\n",
              "      <td>[0, 0, 1, 2]</td>\n",
              "      <td>[[[tensor(-0.1823, dtype=torch.float64), tenso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>'Fair enough, if that's how you want to look a...</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[[[tensor(-0.0953, dtype=torch.float64), tenso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>'He doesn't want to go on the trip without me,...</td>\n",
              "      <td>[1, 0, 1, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[[[tensor(-0.1624, dtype=torch.float64), tenso...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b83fcfe4-9bf3-4dbd-88b9-cca80947129b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b83fcfe4-9bf3-4dbd-88b9-cca80947129b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b83fcfe4-9bf3-4dbd-88b9-cca80947129b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e38a10e3-cc89-4537-83e6-352afc892e68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e38a10e3-cc89-4537-83e6-352afc892e68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e38a10e3-cc89-4537-83e6-352afc892e68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pandas",
              "summary": "{\n  \"name\": \"df_pandas\",\n  \"rows\": 2082,\n  \"fields\": [\n    {\n      \"column\": \"I/E\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N/S\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T/F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"J/P\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2082,\n        \"samples\": [\n          \"'Oh for SURE, there is no doubt that an INFJ can be EQUALLY manipulative! I didn't mean to say that we were the angels.  And when I say manipulative, I don't necessarily mean it in a bad way. After...|||I'd be cremated and tossed into the sea. Hopefully no whales turn their heads in disgust.|||ENFJ,  You break my heart. I want to break your neck. Instead, I'll just stay in my corner and write about how angry I am.|||I cannot - for the life of me - think well (or even effectively) on my feet, so in terms of hotfire debates where two sides are spitting out perspectives, heck no I hate them! I am a sit and stew...|||It might just be me and the INFJ friendships I have. As INFJs, I think that we can understand how a fellow INFJ can come to this or that conclusion, or feel this or that way. We get each other. But I...|||My best and worst experience. I think for two people (INFJ/ENFJ) who really want to strip down to the bareness of their souls, the potential is overwhelming. But of all people for INFJs to open their...|||I have not been in a romantic relationship, but I have a close friend who is INTP and he's a close friend BECAUSE he's an INTP (his INTP-ness makes him worthy :P).  I find his somewhat lack of...|||I wish I had an INFJ friend who I wasn't afraid of opening up to.|||I know an ENFJ very, very well. They are the best and worst for INFJs, IMO. We are not just talking about incompatibility, you will always have that. ENFJs can break your heart and mend it at the...|||Maybe his girlfriend asked him to get it?|||An INTP told me that he feels 100% open with me. Whoa.  ----  I started PerC when I first started my graduate program. Along the way I got sick with an underactive thyroid and experienced a shit...|||I came on to this forum because I knew someone else would understand! Hugs all around.   I've been there with the whole having a romantic relationship where the other person couldn't dig deeper. I...|||From personal experience, it's hard. The door slam is like your stance on a person - they were deserving enough of it (possibly), so still remaining in contact with them would feel like betraying...|||Today, I was presented with this question:  How do your primary relationships feel to you? (i.e., loving, supportive, tense, charged, etc.)  How would you answer?     To be honest, it hit...|||My relationship with my ENFJ only solidifies my belief in a loving, merciful God.|||Life is really one big mind fuck isn't it?|||You are sweet.|||I feel like I've shuttered myself from people so much and so often that I've started doing it to myself as well. I don't even know if I am dealing with my own heartbreak or if I actually feel fine.|||I laugh when people think they know me.|||I was engaged. Now I am not engaged. We got along well, and I felt accepted. Now it just feels like I'm sucked back into a void.|||I actually haven't been engaged for almost four months, but it's only really hitting me now. I'm going to be alone forever.|||To have it all - would be nice, right?  Very true. When presented the option of being understood or being accepted, I'd rather be accepted. It's too lonely otherwise.|||I'm happy that you haven't found anyone else like me.|||The holiday blues got me. It only took me a week to realize it (a week of being sick, no exercise, not being able to sleep and sleeping in - it was too cold).   A quick mention to others and they...|||I can be better than this.|||Life, essentially.  I moved once to get out of my old situation, not out of necessity but to kick myself in the rear. Loved it. Things were clean.  Moved again because of life, out of necessity,...|||I have moved 3 times in the last 8 months. Please life, slow down, let me recharge.|||I'm writing this before reading all the responses (for some reason I feel like I have to state this).  I've been told by an ENFJ that I want to be mysterious and be figured out. I always took...|||From time to time I think about what it means to be an INFJ and sometimes I go through websites and such that describe what it's like to be an INFJ. I came across this video about INFJs that...|||I'm feeling so pathetic.|||Sometimes at random locations I have hours long talks with strangers.  I walk away thinking nothing of it, except perhaps how sorry I am to take up so much of someone's time.  What I'm most...|||I'm not much of a luxury goods person. I like my technology (e.g., iPads, iPhones, MacBooks) though. Clothing+accessories wise, probably my Chanel sunnies. I have a wide face and they actually fit,...|||I'm faced with the difficulty of knowing whats right and whats wrong, and acting on my impulses. This is one of the most frustrating things about being an INFJ, in my experience. For once I want to...|||Why, thesis? Why do you torment me so?|||I have a habit of opening doors for the older folks that come in through Starbucks. There's an old man who's very sweet that I will get up and hold the door while he pushes his walker out. He comes...|||Honeymoon Avenue. I can't get it out of my head!|||I pretty much bowl over on cheap puns. Yeah, doesn't take much for me.|||Dear INTP, I sort of miss you and talking to you. I felt grounded when speaking with you - I felt heard, I felt an attempt at understanding, and I felt like for once I wasn't speaking into empty...|||Sometimes I think I need grief counseling, but there's nothing they could say to me that I haven't already said to myself.|||I look at pictures with my hair long and want to cry. It's so weird how I was attached to it. I don't feel like me! And instead I wear a pony all the time now because I hate the way it looks....|||I wish this existed in real life. I need this for persuasion purposes in order to get my way.|||ENFJ,  For once I wish you would just stop whining about the circumstances of our relationship and just be there for me like you claim you are. I don't know how to freaking reach out to you,...|||I cut a foot or so off the length of my hair. I am so sad.|||Feeling like such a failure today.|||I feel like my life has been suspended since March 2013.|||In the next week i'll be teaching again. Ugh, God save me|||All I can say is ALL THE DAMN TIME. I don't have any advice, it just seems to hurt like an open wound always.|||Today is a day where I feel very afraid.|||One of my new years resolutions is to stop being so afraid ... but I can't.|||Sometimes I wish you would float away and reintroduce your soul in some other way because I really want to love you but can't allow you as you are now to hurt me again.'\",\n          \"'.|||Thank you. It's the first time I've tried to paint a landscape.|||691162  I'll probably add more to this tomorrow|||That's helpful thanks! I think moral of the story is use yellow sparingly lol.|||Hi. I feel like I've messed up several oil paintings because the paint colors get too muddy. Do I wait for it to dry then paint over it? Do I thin it out with mineral spirits? Do I add a shit ton of...|||aw yea :encouragement:|||I like your eyeliner.|||Sophia from the Golden Girls lolol|||653314  Meh|||I'd say my favorite types are ENTP, ENFP, INTP, ESFP, ESFJ. Mostly becuase those are my friends. I don't get along ENFJs or INFPs as well.|||What the hell is C#?   652810  This?|||648386|||647818  Have another|||I'm 1/3 native american and the rest white. No one seems to really know what I am except for other indians.|||647762  Trying to decide if I should add more. I'm thinking about some orange clouds or something lol. But I might regret it. I'm just waiting for it to dry then maybe|||I would go ask this question in another section of the forum LOL|||God's stopped answering. Honestly what else would you expect HA|||I'd assume you're gay. So.. your choice. Kinda sucks that a pattern is like off limits to straight guys. Yall have it so hard|||receipts planner pens lip balm red lipstick face powder retractable powder brush a bag of pretzels water bottle tampons|||My friend said so i got hit in the clam... in coversation the other day and I laughed so hard. CLAM It's a four lettered c word that means the same thing|||Infp.|||I also want to say, and I'm usually no kiss ass, but ENTP's are indubitably the best MBTI type.|||I know lots of INTPs. First impression is always like oh they're so quiet and sweet and nice.  Then they say something really weird and random outta left field and you're like Ohhh, I get it. I...|||No you guys should spend more time together. Don't be shy, ask if he wants to hang out or something. Usually we say what we mean, so if he says you're better than other girls then by god take his...|||Yeah, I mean it sounds cold when you explain it. But deep inside if I like you I want to hear about your day and your problems. But I want to talk to you in person. I like people who just say...|||I hate having to text someone daily. If I'm dating someone I might text them once a week. I don't want to know your every waking move ugh. Course I'll answer them if they wanna talk to me. But I'd...|||No actually not at all. Couldn't give a fuck.|||Nah you're right. I know some ISTPs who are total losers. I honestly think MBTI means almost nothing. People are different.|||Me too. 645578  Basically I got really pissed off at this lady from work who always tries to be my boss when she's not. Later that night I drunkenly printed this out and taped it to my kitchen...|||Dude ENTPs are the best. Yall got no filter and I love that|||645122  OK... this is me|||Oh for gods sake|||Lol I might get up in the morning at 5|||The following panel he says something like wow i really need to get laid|||Great input, yall. Very elaborate LOL|||(v)isuals  I mostly post art so it goes with this forum I guess|||639010  This actually kind of looks like the guy i was trying to draw.. so that's a win I guess. He was sleeping.|||638994 639002  Preacher was the best. It's too bad that tv show was so god awful.|||Everyone says they're most compatible with us but I'm not so sure from my experience. It kind of seems like they're extremely similar but also kind of a mystery to me. I think it has to do with...|||I won't break the rules if the rules work. If the rules suck I'll do it a different way and usually people don't mind after they see the results. I don't break the rules unless it's to make something...|||I dated one. It was kind of nice because I felt like we knew exactly what the other was thinking. Didn't have to explain shit... Had similar sense a humor. But it's crazy how we can be so similar and...|||My best friend is an ISTP, so yeah. Why?|||Im going to send this to my boss lol he'll understand.|||Oh my GOD this is so fucking cathartic to me.|||When you said I fail at typing I thought what did I misspell? lol. No, I know this INFJ well. He uses sharpie to fill in the gray hairs in his sideburns.|||One time I was in an INFJ's house, and they left for a moment. So I made all the pictures hanging on the walls slightly crooked, I unfluffed the couch pillows, I wrinkled the rug slightly, I opened a...|||LOL that's pretty accurate. I remember when you made the most average-ass lasagna ever, and then gloated about how good it was for an entire week after. Shit had zuchinni chunks and ricotta cheese in...|||OK that's fair but ENTP you know I like to play guitar as much as you do but you would NEVER let me touch your precious banjo. And I would sit on the floor and listen to you cover fucking radiohead...|||ENTP, I dated one of you. Thought you were comletely normal and then a couple months in you fucking tell me you believe in reptilian humanoids. Your avatar is interestingly sort of coincidental.|||How do you fit and differ from ISTP stereotypes? I'm kind of hot headed, not the mello-ist person. Also am more orderly than sterotypical  Also, have you grown up being misunderstood or feeling...'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"True\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filtered\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attributions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array(list(df_pandas['True']))\n",
        "y_pred = np.array(list(df_pandas['raw']))\n",
        "\n",
        "labels = [\"I/E\", \"N/S\", \"T/F\", \"J/P\"]\n",
        "F1s = []\n",
        "conf_mat_dict={}\n",
        "\n",
        "for label_col in range(len(labels)):\n",
        "    y_true_label = y_true[:, label_col]\n",
        "    y_pred_label = y_pred[:, label_col]\n",
        "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
        "    #tn, fp, fn, tp = confusion_matrix(y_true_label, y_pred_label).ravel()\n",
        "    #print(tn, fp, fn, tp)\n",
        "    print(classification_report(y_true_label, y_pred_label))\n",
        "    dd = classification_report(y_true_label, y_pred_label, output_dict = True)\n",
        "    F1s.append(dd['weighted avg']['f1-score'])"
      ],
      "metadata": {
        "id": "A-HAFzOLKpJZ",
        "outputId": "e82fe051-833b-4f86-e8ea-6c16d11a9fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87      1602\n",
            "           1       0.55      0.29      0.38       480\n",
            "\n",
            "    accuracy                           0.78      2082\n",
            "   macro avg       0.68      0.61      0.62      2082\n",
            "weighted avg       0.75      0.78      0.76      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1795\n",
            "           1       0.46      0.18      0.26       287\n",
            "\n",
            "    accuracy                           0.86      2082\n",
            "   macro avg       0.67      0.57      0.59      2082\n",
            "weighted avg       0.82      0.86      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       955\n",
            "           1       0.72      0.69      0.70      1127\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.69      0.69      0.69      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.56      0.55       824\n",
            "           1       0.71      0.70      0.70      1258\n",
            "\n",
            "    accuracy                           0.64      2082\n",
            "   macro avg       0.63      0.63      0.63      2082\n",
            "weighted avg       0.64      0.64      0.64      2082\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getF1s(df_pandas):\n",
        "\n",
        "  y_true = np.array(list(df_pandas['True']))\n",
        "  y_pred = np.array(list(df_pandas['exp']))\n",
        "\n",
        "  labels = [\"I/E\", \"N/S\", \"T/F\", \"J/P\"]\n",
        "\n",
        "  conf_mat_dict={}\n",
        "  updated_F1s = []\n",
        "\n",
        "  for label_col in range(len(labels)):\n",
        "      y_true_label = y_true[:, label_col]\n",
        "      y_pred_label = y_pred[:, label_col]\n",
        "      indices = np.where(y_pred_label == 2)\n",
        "      np.put(y_true_label, indices, 2)\n",
        "      #y_true_label = np.delete(y_true_label, indices[0])\n",
        "      #y_pred_label = np.delete(y_pred_label, indices[0])\n",
        "      conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
        "      print(classification_report(y_true_label, y_pred_label))\n",
        "      dd = classification_report(y_true_label, y_pred_label, output_dict = True)\n",
        "      updated_F1s.append(dd['weighted avg']['f1-score'])\n",
        "\n",
        "  return updated_F1s"
      ],
      "metadata": {
        "id": "SBf5IZN2K7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refine(attributions, label, threshold):\n",
        "\n",
        "  attribution_th = []\n",
        "  for i in range(0,4):\n",
        "\n",
        "            if(checkThreshold(attributions[i], label = int(label[i]), threshold = threshold)):\n",
        "                attribution_th.append(label[i])\n",
        "            else:\n",
        "                attribution_th.append(2)\n",
        "\n",
        "  return attribution_th"
      ],
      "metadata": {
        "id": "48sF1pfAWNRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search for lower and upper limit"
      ],
      "metadata": {
        "id": "x-_B5Ijqxjdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ran = np.arange(-1, 0, 0.2, dtype=float)\n",
        "for i in ran:\n",
        "  print('Lower: ' ,i)\n",
        "  df_pandas['exp'] = df_pandas.apply(lambda x: refine(x['attributions'], x['raw'], threshold = [i, 0.6]), axis=1)\n",
        "  f1 = getF1s(df_pandas)\n",
        "  print(f1)"
      ],
      "metadata": {
        "id": "qc7xTG1GSf0j",
        "outputId": "dac7f49b-5a28-498c-a2ad-7eae0cef10df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower:  -1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1468\n",
            "           1       0.47      0.10      0.16       365\n",
            "           2       1.00      1.00      1.00       249\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.78      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1679\n",
            "           1       0.35      0.06      0.10       229\n",
            "           2       1.00      1.00      1.00       174\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.75      0.68      0.68      2082\n",
            "weighted avg       0.84      0.88      0.85      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.50      0.58       589\n",
            "           1       0.72      0.85      0.78       888\n",
            "           2       1.00      1.00      1.00       605\n",
            "\n",
            "    accuracy                           0.79      2082\n",
            "   macro avg       0.80      0.78      0.79      2082\n",
            "weighted avg       0.79      0.79      0.79      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.66      0.60       619\n",
            "           1       0.69      0.59      0.64       813\n",
            "           2       1.00      1.00      1.00       650\n",
            "\n",
            "    accuracy                           0.74      2082\n",
            "   macro avg       0.75      0.75      0.74      2082\n",
            "weighted avg       0.75      0.74      0.74      2082\n",
            "\n",
            "[0.7720163519082139, 0.8462409219460553, 0.7862015523159268, 0.7379218770100474]\n",
            "Lower:  -0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1502\n",
            "           1       0.47      0.09      0.16       373\n",
            "           2       1.00      1.00      1.00       207\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.77      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1737\n",
            "           1       0.35      0.05      0.09       241\n",
            "           2       1.00      1.00      1.00       104\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.74      0.68      0.68      2082\n",
            "weighted avg       0.83      0.88      0.84      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.59      0.62       711\n",
            "           1       0.72      0.78      0.75       965\n",
            "           2       1.00      1.00      1.00       406\n",
            "\n",
            "    accuracy                           0.76      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.75      0.76      0.75      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.67      0.60       643\n",
            "           1       0.69      0.57      0.62       844\n",
            "           2       1.00      1.00      1.00       595\n",
            "\n",
            "    accuracy                           0.72      2082\n",
            "   macro avg       0.74      0.75      0.74      2082\n",
            "weighted avg       0.73      0.72      0.72      2082\n",
            "\n",
            "[0.7665587718790087, 0.8379097738211967, 0.7544038073885057, 0.722826633139031]\n",
            "Lower:  -0.6000000000000001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1523\n",
            "           1       0.47      0.09      0.16       374\n",
            "           2       1.00      1.00      1.00       185\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.77      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1750\n",
            "           1       0.35      0.05      0.09       248\n",
            "           2       1.00      1.00      1.00        84\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.74      0.68      0.67      2082\n",
            "weighted avg       0.82      0.88      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.65      0.65       840\n",
            "           1       0.72      0.73      0.72      1037\n",
            "           2       1.00      1.00      1.00       205\n",
            "\n",
            "    accuracy                           0.72      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.72      0.72      0.72      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61       667\n",
            "           1       0.69      0.56      0.62       855\n",
            "           2       1.00      1.00      1.00       560\n",
            "\n",
            "    accuracy                           0.72      2082\n",
            "   macro avg       0.75      0.75      0.74      2082\n",
            "weighted avg       0.73      0.72      0.72      2082\n",
            "\n",
            "[0.7657939993729879, 0.8330872579622722, 0.7221822167598521, 0.7171002565479296]\n",
            "Lower:  -0.40000000000000013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1527\n",
            "           1       0.47      0.09      0.16       375\n",
            "           2       1.00      1.00      1.00       180\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.77      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1759\n",
            "           1       0.35      0.05      0.09       248\n",
            "           2       1.00      1.00      1.00        75\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.74      0.68      0.67      2082\n",
            "weighted avg       0.82      0.88      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.66       915\n",
            "           1       0.72      0.70      0.71      1084\n",
            "           2       1.00      1.00      1.00        83\n",
            "\n",
            "    accuracy                           0.70      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.70      0.70      0.70      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61       670\n",
            "           1       0.69      0.56      0.62       858\n",
            "           2       1.00      1.00      1.00       554\n",
            "\n",
            "    accuracy                           0.72      2082\n",
            "   macro avg       0.75      0.75      0.74      2082\n",
            "weighted avg       0.73      0.72      0.72      2082\n",
            "\n",
            "[0.7651126767300902, 0.8330701868953084, 0.7001617948719685, 0.715605616473418]\n",
            "Lower:  -0.20000000000000018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1528\n",
            "           1       0.47      0.09      0.16       375\n",
            "           2       1.00      1.00      1.00       179\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.77      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1759\n",
            "           1       0.35      0.05      0.09       249\n",
            "           2       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.74      0.68      0.67      2082\n",
            "weighted avg       0.82      0.88      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.69      0.67       946\n",
            "           1       0.72      0.68      0.70      1104\n",
            "           2       1.00      1.00      1.00        32\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61       671\n",
            "           1       0.69      0.56      0.62       859\n",
            "           2       1.00      1.00      1.00       552\n",
            "\n",
            "    accuracy                           0.71      2082\n",
            "   macro avg       0.75      0.75      0.74      2082\n",
            "weighted avg       0.73      0.71      0.72      2082\n",
            "\n",
            "[0.7651078117494694, 0.8323847759763422, 0.6906203962915838, 0.7151069840861364]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ran = np.arange(0, 1, 0.2, dtype=float)\n",
        "for i in ran:\n",
        "  print('Upper: ' ,i)\n",
        "  df_pandas['exp'] = df_pandas.apply(lambda x: refine(x['attributions'], x['raw'], threshold = [-0.1, i]), axis=1)\n",
        "  f1 = getF1s(df_pandas)\n",
        "  print(f1)"
      ],
      "metadata": {
        "id": "4MVF5KYXYtB8",
        "outputId": "bacd136c-7efa-4c93-bf72-eb397412be81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upper:  0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87      1602\n",
            "           1       0.55      0.29      0.38       480\n",
            "\n",
            "    accuracy                           0.78      2082\n",
            "   macro avg       0.68      0.61      0.62      2082\n",
            "weighted avg       0.75      0.78      0.76      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1795\n",
            "           1       0.46      0.18      0.26       287\n",
            "\n",
            "    accuracy                           0.86      2082\n",
            "   macro avg       0.67      0.57      0.59      2082\n",
            "weighted avg       0.82      0.86      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       954\n",
            "           1       0.72      0.69      0.70      1127\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.56      0.55       824\n",
            "           1       0.71      0.70      0.70      1258\n",
            "\n",
            "    accuracy                           0.64      2082\n",
            "   macro avg       0.63      0.63      0.63      2082\n",
            "weighted avg       0.64      0.64      0.64      2082\n",
            "\n",
            "[0.7559277827380696, 0.8297163238377242, 0.6868008920360709, 0.6417525493021689]\n",
            "Upper:  0.2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87      1594\n",
            "           1       0.54      0.26      0.35       461\n",
            "           2       1.00      1.00      1.00        27\n",
            "\n",
            "    accuracy                           0.79      2082\n",
            "   macro avg       0.78      0.73      0.74      2082\n",
            "weighted avg       0.75      0.79      0.76      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92      1794\n",
            "           1       0.45      0.17      0.25       284\n",
            "           2       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.86      2082\n",
            "   macro avg       0.78      0.71      0.72      2082\n",
            "weighted avg       0.82      0.86      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       954\n",
            "           1       0.72      0.69      0.70      1127\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.56      0.55       813\n",
            "           1       0.71      0.69      0.70      1247\n",
            "           2       1.00      1.00      1.00        22\n",
            "\n",
            "    accuracy                           0.65      2082\n",
            "   macro avg       0.75      0.75      0.75      2082\n",
            "weighted avg       0.65      0.65      0.65      2082\n",
            "\n",
            "[0.7570439217859877, 0.8295692426531998, 0.6868008920360709, 0.6474135178749969]\n",
            "Upper:  0.4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.95      0.88      1563\n",
            "           1       0.51      0.18      0.27       416\n",
            "           2       1.00      1.00      1.00       103\n",
            "\n",
            "    accuracy                           0.80      2082\n",
            "   macro avg       0.77      0.71      0.72      2082\n",
            "weighted avg       0.76      0.80      0.76      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93      1779\n",
            "           1       0.43      0.12      0.19       269\n",
            "           2       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           0.87      2082\n",
            "   macro avg       0.77      0.70      0.71      2082\n",
            "weighted avg       0.82      0.87      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       954\n",
            "           1       0.72      0.69      0.70      1127\n",
            "           2       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.61      0.58       752\n",
            "           1       0.71      0.65      0.68      1092\n",
            "           2       1.00      1.00      1.00       238\n",
            "\n",
            "    accuracy                           0.68      2082\n",
            "   macro avg       0.75      0.75      0.75      2082\n",
            "weighted avg       0.68      0.68      0.68      2082\n",
            "\n",
            "[0.7622239267199946, 0.83164271792907, 0.6868008920360709, 0.6779314255791945]\n",
            "Upper:  0.6000000000000001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.89      1528\n",
            "           1       0.47      0.09      0.16       375\n",
            "           2       1.00      1.00      1.00       179\n",
            "\n",
            "    accuracy                           0.82      2082\n",
            "   macro avg       0.76      0.69      0.68      2082\n",
            "weighted avg       0.77      0.82      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      1759\n",
            "           1       0.35      0.05      0.09       249\n",
            "           2       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.74      0.68      0.67      2082\n",
            "weighted avg       0.82      0.88      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.69      0.67       947\n",
            "           1       0.72      0.68      0.70      1105\n",
            "           2       1.00      1.00      1.00        30\n",
            "\n",
            "    accuracy                           0.69      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.69      0.69      0.69      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61       671\n",
            "           1       0.69      0.56      0.62       859\n",
            "           2       1.00      1.00      1.00       552\n",
            "\n",
            "    accuracy                           0.71      2082\n",
            "   macro avg       0.75      0.75      0.74      2082\n",
            "weighted avg       0.73      0.71      0.72      2082\n",
            "\n",
            "[0.7651078117494694, 0.8323847759763422, 0.690143370437174, 0.7151069840861364]\n",
            "Upper:  0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89      1507\n",
            "           1       0.45      0.04      0.08       355\n",
            "           2       1.00      1.00      1.00       220\n",
            "\n",
            "    accuracy                           0.83      2082\n",
            "   macro avg       0.76      0.68      0.66      2082\n",
            "weighted avg       0.77      0.83      0.76      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1740\n",
            "           1       0.50      0.02      0.04       241\n",
            "           2       1.00      1.00      1.00       101\n",
            "\n",
            "    accuracy                           0.88      2082\n",
            "   macro avg       0.79      0.67      0.66      2082\n",
            "weighted avg       0.84      0.88      0.83      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.72      0.68       910\n",
            "           1       0.72      0.65      0.68      1000\n",
            "           2       1.00      1.00      1.00       172\n",
            "\n",
            "    accuracy                           0.71      2082\n",
            "   macro avg       0.79      0.79      0.79      2082\n",
            "weighted avg       0.71      0.71      0.71      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.81      0.65       568\n",
            "           1       0.71      0.42      0.53       656\n",
            "           2       1.00      1.00      1.00       858\n",
            "\n",
            "    accuracy                           0.76      2082\n",
            "   macro avg       0.75      0.74      0.73      2082\n",
            "weighted avg       0.79      0.76      0.76      2082\n",
            "\n",
            "[0.764998093922141, 0.8345832862790277, 0.7074704249191002, 0.7561840424605555]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pandas['exp'] = df_pandas.apply(lambda x: refine(x['attributions'], x['raw'], threshold = [-1, 0.8]), axis=1)\n",
        "updated_F1s = getF1s(df_pandas)\n",
        "print(updated_F1s)"
      ],
      "metadata": {
        "id": "cqRir10WYfxk",
        "outputId": "e747ce0c-a7e7-49d2-c5e6-6d8fbedc760e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89      1447\n",
            "           1       0.45      0.04      0.08       345\n",
            "           2       1.00      1.00      1.00       290\n",
            "\n",
            "    accuracy                           0.83      2082\n",
            "   macro avg       0.76      0.68      0.66      2082\n",
            "weighted avg       0.78      0.83      0.77      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      1660\n",
            "           1       0.50      0.02      0.04       221\n",
            "           2       1.00      1.00      1.00       201\n",
            "\n",
            "    accuracy                           0.89      2082\n",
            "   macro avg       0.79      0.67      0.66      2082\n",
            "weighted avg       0.85      0.89      0.85      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.53      0.60       552\n",
            "           1       0.72      0.83      0.77       783\n",
            "           2       1.00      1.00      1.00       747\n",
            "\n",
            "    accuracy                           0.81      2082\n",
            "   macro avg       0.80      0.79      0.79      2082\n",
            "weighted avg       0.81      0.81      0.81      2082\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.79      0.65       516\n",
            "           1       0.71      0.45      0.55       610\n",
            "           2       1.00      1.00      1.00       956\n",
            "\n",
            "    accuracy                           0.79      2082\n",
            "   macro avg       0.75      0.75      0.73      2082\n",
            "weighted avg       0.80      0.79      0.78      2082\n",
            "\n",
            "[0.7720049003539433, 0.848544758170657, 0.8067152089763484, 0.7812261760912528]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting before and after with threshold = [-1, 0.8]"
      ],
      "metadata": {
        "id": "qEqzXnaWx1Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_F1s = [i*100 for i in updated_F1s]\n",
        "F1s = [i*100 for i in F1s]"
      ],
      "metadata": {
        "id": "XAZMPP9LnwIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# X-axis values (indices)\n",
        "x = range(len(F1s))\n",
        "\n",
        "# Plotting the bars\n",
        "plt.bar(x, F1s, width=0.4, label='Before Refining', align='center', color = 'blue')\n",
        "plt.bar(x, updated_F1s, width=0.4, label='After Refining', align='edge')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Dimensions')\n",
        "plt.ylabel('F1 Scores')\n",
        "plt.title('Comparison of labels')\n",
        "plt.xticks(x, labels)\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Za-Ye3ndKxO_",
        "outputId": "30f68743-5a48-4b6f-9131-73cfcea11d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}